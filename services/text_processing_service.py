import re
from services.translation_services import translate_text
from services.keywords_services import text_to_keyword
from services.hangul_service import hangul_text
from services.db_service import save_text_processing_result

class TextProcessingService:
    def __init__(self):
        self.translation_service = translate_text()
        self.keyword_service = text_to_keyword()
        self.hangul_service = hangul_text()

    def count_korean_chars(self, text: str) -> int:
        """í•œê¸€ ë¬¸ì ê°œìˆ˜"""
        return len(re.findall(r"[ê°€-í£]", text))

    def count_english_chars(self, text: str) -> int:
        """ì˜ì–´ ë¬¸ì ê°œìˆ˜"""
        return len(re.findall(r"[a-zA-Z]", text))

    def clean_text(self, text: str) -> str:
        """ê³µë°± ì œê±° ë° í•œê¸€ ìëª¨ ê²°í•©"""
        text = re.sub(r"\s+", "", text)  # ëª¨ë“  ê³µë°± ì œê±°
        text = self.hangul_service.join_hangul(text)  # í•œê¸€ ìëª¨ ê²°í•©
        return text

    def process_text(self, text: str):
        """
        1. ë²ˆì—­ì„ ë¨¼ì € ì‹œë„
        2. ë²ˆì—­ í›„ í•œê¸€ì´ ë§ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì˜ì–´ê°€ ë§ìœ¼ë©´ í•œê¸€ ìíŒ ë³€í™˜
        3. í•œê¸€ ìëª¨ ì¡°í•© (ã…‡ã…ã„´ã„´ã…•ã…‡ â†’ ì•ˆë…•)
        4. í‚¤ì›Œë“œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ, ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´ ì œê±°)
        5. ë°ì´í„° ì €ì¥
        """

        text = text.strip()  # ì•ë’¤ ê³µë°± ì œê±°

        # **ğŸ”¹ 1) ë²ˆì—­ ë¨¼ì € ìˆ˜í–‰**
        translated_text = self.translation_service.translate_to_ko(text)

        # **ğŸ”¹ 2) ë²ˆì—­ëœ ë¬¸ì¥ì—ì„œ í•œê¸€ vs ì˜ì–´ ê°œìˆ˜ ë¹„êµ**
        korean_count = self.count_korean_chars(translated_text)
        english_count = self.count_english_chars(translated_text)

        if korean_count >= english_count:
            processed_text = translated_text  # ë²ˆì—­ëœ ë¬¸ì¥ ì‚¬ìš©
        else:
            processed_text = self.hangul_service.ko_to_eng_keyboard(text)  # í•œê¸€ ìíŒ ë³€í™˜

        # **ğŸ”¹ 3) í•œê¸€ ìëª¨ ì¡°í•© (ì¡°í•©ë˜ì§€ ì•Šì€ ë¬¸ì ì²˜ë¦¬)**
        processed_text = self.hangul_service.join_hangul(processed_text)

        # **ğŸ”¹ 4) í‚¤ì›Œë“œ ì¶”ì¶œ (ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°)**
        keywords = self.keyword_service.extract_nouns(processed_text)
        keywords = list(set(filter(lambda x: len(x) >= 1, keywords)))  # 2ê¸€ì ì´ìƒ ë‹¨ì–´ë§Œ ìœ ì§€

        # **ğŸ”¹ 5) í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ê³µë°± ì œê±° ë° ë‹¤ì‹œ í•œê¸€ ì¡°í•©**
        if not keywords:
            processed_text = self.clean_text(processed_text)

        # **ğŸ”¹ 6) ê²°ê³¼ ì €ì¥**
        save_text_processing_result(text, processed_text, keywords)

        return {"original_text": text, "processed_text": processed_text, "keywords": keywords}
